---
redirect_from: /_posts/2024-11-29-%4
title: tensor探析
tags:
  - 概念学习
---

> ”我们习惯用线性的方式理解世界，就像将地平线看作一条直线，但实际上每条直线后面都有无尽的曲折。“
>
> "We are accustomed to understanding the world in a linear way, just as we see the horizon as a straight line, but behind every straight line lies an infinity of curves" 

在学习机器学习编程的过程中，我疑惑于张量与数组的区别，还隐隐意识到似乎与物理上的张量有所差别。带着疑问，我将非公理化地了解物理与数学上的张量为何物，探寻其在机器学习中的作用。

## 物理&数学

张量（tensor）的概念早在19世纪末就被数学家提出并得以发展：萌芽于德国数学家欧拉和高斯研究曲面和形变问题；发展于柯西用来描述力学应力的张量形式、黎曼引入度量张量描述弯曲空间中的距离关系；最终由意大利数学家里奇和其学生埃利·嘉当建立张量分析的形式化理论，并将概念推广到了更广泛的几何和代数领域。

但这个概念真正发扬光大, 还要归功于爱因斯坦相对论的提出。原因是：虽然物理定律在惯性参考系中是相同的，但在相对论中，在不同参考系下看同一个物理系统是不一样的，物理量在不同坐标系下的转换问题变得更加重要。而在描述时空的结构和引力场时，爱因斯坦成功使用了黎曼曲率张量和应力-能量张量等张量来描述物体和引力之间的相互作用，张量作为描述物理现象的基本工具才得到了广泛认同。

如果需要严谨的证明可以点击这个[回答](https://zhuanlan.zhihu.com/p/121429834)。

举个例子来解释，基于狭义相对论的内容，当一个物体相对于观察者高速运动时，它的长度会在运动方向上变短，从运动物体的参考系来看，物体的长度会保持不变，但从静止参考系来看，物体会变得更短... 两个参考系观测到的内容可能并不相同，但都是正确的，通过洛伦兹变换可以得到某个参考系的内容，但我们也可以抽象为一个不随坐标而改变的量，它可以在不同的坐标系里转化为不同的量，这就是张量。

不要求严谨的情况下，我更想这样理解：当我们花费 100元人民币网购时，将你的花费转述给在英国的朋友时也许会说” 10英镑左右“，在这里网购商品的价值量便是我所理解的tensor。

> A tensor is something that transforms like a tensor!          —Anthony Zee

考虑我们所学的线性变换，在一组基下，矩阵表示为 $A$，但在另一组基下，可以表示为 $A'=TAT^{-1}$，这一过程就是通过线性变换实现的，其中的 $T$是基变换矩阵。再考虑到特征矩阵的存在，相似矩阵可以通过一个线性变化在不同基下表示，原来线性代数的学习早就使用了张量的思想。 在数学家眼中, 张量已经被抽象成了[线性变换](https://zhuanlan.zhihu.com/p/433350768)。

## 机器学习

理解编程中的 tensor并不需要对张量的数学与物理理解，可以简单理解为特殊的数组。

tensor是机器学习中的一个通用概念，是数据结构类型，本质上就是一个多维数组，目的是创建更高维度的数据对象。零阶张量指标数 0，为标量（scalar）；一阶张量指标数 1，为向量（vector）；二阶张量指标数为 2，为矩阵（matrix）；以此类推。

那我们为何不适用数组对象呢？NumPy（Numerical Python） 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。但是这一程序库是在 CPU上运行的，为支持机器学习的计算要求，引出 tensor，作为可以放在 GPU中运算的N维数组对象 NDArray，并为学习算法提供额外的功能。例如：

在 pytorch中，当我们创建 tensor对象后进行加减乘除运算时，后台会自动构建出计算图，计算完成后，通过运算结果的 backward函数反向传播后，我们就可以得到计算过程中所有 `requires_grad=True` 的 tensor 的梯度。

基于[锦恢](https://www.zhihu.com/people/can-meng-zhong-de-che-xian)的一份回答

> **深度学习框架最重要的是什么？**答：自动求导系统。
>
> **为什么要自动求导系统？**答：因为目前的损失函数的优化方法全都基于一阶梯度信息进行梯度下降。
>
> **如何实现梯度的计算？**答：计算图。





